{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders data analysis with Sagemaker\n",
    "\n",
    "This notebook will demonstrate how to train and test LinearLearner model on SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import sagemaker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from config import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILENAME = 'train_df.csv'\n",
    "DATA_LOCAL_PATH = 'orders'\n",
    "\n",
    "FULL_S3_INPUT_PATH = os.path.join('s3://', SAGEMAKER_S3_BUCKET, INPUT_S3_PATH, INPUT_FILENAME)\n",
    "FULL_S3_OUTPUT_PATH = os.path.join('s3://', SAGEMAKER_S3_BUCKET, OUTPUT_S3_PATH)\n",
    "\n",
    "ROLE = SAGEMAKER_ROLE_ARN\n",
    "SAGEMAKER_SESSION = sagemaker.Session()\n",
    "\n",
    "CONTAINERS = {\n",
    "    'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/linear-learner:latest',\n",
    "    'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:latest',\n",
    "    'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/linear-learner:latest',\n",
    "    'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/linear-learner:latest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Syncing from $DATA_S3_PATH to $DATA_LOCAL_PATH\"\n",
    "!aws s3 sync \"$DATA_S3_PATH\" \"$DATA_LOCAL_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders_df(data_path):\n",
    "    paths = os.listdir(data_path)\n",
    "    partial_order_dfs = [pd.read_json(os.path.join(data_path, path), lines=True) for path in paths]\n",
    "    orders_df = pd.concat(partial_order_dfs, copy=False)\n",
    "    orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])\n",
    "    return orders_df\n",
    "\n",
    "\n",
    "def split_train_test_df(daily_profit_df):\n",
    "    datetime_index = pd.to_datetime(daily_profit_df.index)\n",
    "    datetime_index_in_days = np.array(datetime_index).astype('datetime64[D]')\n",
    "    x = np.array(pd.to_numeric(datetime_index_in_days)) \n",
    "    y = daily_profit_df['profit']\n",
    "\n",
    "    return train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "def profit_by_period(orders_df, date_period):\n",
    "    if date_period == 'day':\n",
    "        time_grouper = pd.TimeGrouper('D')\n",
    "    else:\n",
    "        time_grouper = pd.TimeGrouper('M')\n",
    "    return orders_df.set_index('order_date').groupby(time_grouper).sum().rename({'price': 'profit'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_prices(orders_df):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    orders_df['price'].plot.hist(bins=100)\n",
    "    \n",
    "    \n",
    "def plot_df_by_date(orders_df, date_period):\n",
    "    profit_by_date = profit_by_period(orders_df, date_period)\n",
    "    profit_by_date.plot(figsize=(20,10))\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_regression_report(x, y, y_pred, scaler=None):        \n",
    "    x_time_int = pd.Series(np.rint(x.reshape(-1)))\n",
    "    x_time = pd.to_datetime(x_time_int, unit='d')\n",
    "\n",
    "    print('Test scores:')\n",
    "    print('R2:', r2_score(y, y_pred))\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y, y_pred)))\n",
    "    \n",
    "    pred_df = pd.DataFrame({'profit': y, 'predicted_profit': y_pred}, index=x_time)\n",
    "    pred_df.plot(figsize=(20, 10))\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data_to_dataframe(x, y):\n",
    "    train_df = pd.DataFrame({'x': x.reshape(-1), 'y': y})\n",
    "    return train_df.reindex(['y', 'x'], axis=1)\n",
    "\n",
    "\n",
    "def upload_sagemaker_input(df, sagemaker_bucket, input_s3_path, input_filename):\n",
    "    df.to_csv(input_filename, index=False, header=False)\n",
    "    input_s3_key = os.path.join(input_s3_path, input_filename)\n",
    "    print('Putting input data to {}'.format(os.path.join(sagemaker_bucket, input_s3_key)))\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.upload_file(\n",
    "        Bucket=sagemaker_bucket,\n",
    "        Key=input_s3_key,\n",
    "        Filename=input_filename\n",
    "    )\n",
    "    \n",
    "\n",
    "def create_sagemaker_linear_regression(train_instance_type, model_name, output_path, mini_batch_size=10):     \n",
    "    linear_regression = sagemaker.estimator.Estimator(\n",
    "        CONTAINERS[REGION_NAME],\n",
    "        ROLE, \n",
    "        train_instance_count=1, \n",
    "        train_instance_type=train_instance_type,\n",
    "        output_path=output_path,\n",
    "        sagemaker_session=SAGEMAKER_SESSION\n",
    "    )\n",
    "\n",
    "    linear_regression.set_hyperparameters(\n",
    "        feature_dim=1,\n",
    "        predictor_type='regressor',\n",
    "        loss='squared_loss',\n",
    "        wd=1e-4,\n",
    "        optimizer='sgd',\n",
    "        learning_rate=0.1,\n",
    "        mini_batch_size=mini_batch_size,\n",
    "        epochs=5\n",
    "    )\n",
    "    \n",
    "    return linear_regression\n",
    "\n",
    "\n",
    "def predict_with_sagemaker(sagemaker_predictor, x):\n",
    "    result = sagemaker_predictor.predict(x)\n",
    "    predictions = result['predictions']\n",
    "    return np.array([prediction['score'] for prediction in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = load_orders_df(DATA_LOCAL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Let's explore orders using visual analysis and select an algorithm to predict future sales profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orders price distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prices(orders_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_by_date(orders_df, 'month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_by_date(orders_df, 'day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "We need to convert data into proper format and split into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_profit_df = profit_by_period(orders_df, 'day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_train_test_df(daily_profit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to S3\n",
    "\n",
    "The code below will upload training data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = training_data_to_dataframe(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_sagemaker_input(train_df, SAGEMAKER_S3_BUCKET, INPUT_S3_PATH, INPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Sagemaker's Linear Learner\n",
    "Model training requires specyfing where data is located and what type of instance we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_linear_regression = create_sagemaker_linear_regression(\n",
    "    train_instance_type=SAGEMAKER_TRAINING_INSTANCE_TYPE,\n",
    "    model_name=MODEL_NAME,\n",
    "    output_path=FULL_S3_OUTPUT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_linear_regression.fit(\n",
    "    {\n",
    "        'train': sagemaker.s3_input(\n",
    "            FULL_S3_INPUT_PATH,\n",
    "            content_type='text/csv'\n",
    "        )\n",
    "    },\n",
    "    logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model to an endpoint\n",
    "\n",
    "After training, we use fitted object to build and deploy model. This creates a SageMaker endpoint that can be used to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor = sagemaker_linear_regression.create_model(name=MODEL_NAME).deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=SAGEMAKER_HOSTING_INSTANCE_TYPE,\n",
    "    endpoint_name=ENDPOINT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = sagemaker.predictor.csv_serializer\n",
    "linear_predictor.deserializer = sagemaker.predictor.json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results\n",
    "Using the deployed endpoint we can check accuracy of our model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_with_sagemaker(linear_predictor, x_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_report(x_test, y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

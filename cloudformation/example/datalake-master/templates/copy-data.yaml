AWSTemplateFormatVersion: '2010-09-09'
Description: AWS CloudFormation template to copy data to Datalake buckets (qs-1nlkhq1no)
Resources:
  CopyData:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt 'CopyDataFunction.Arn'
      SubmissionsBucket: !Ref 'SubmissionsBucketName'
      CuratedBucket: !Ref 'CuratedBucketName'
      DatasetBucket: !Ref 'DatasetS3BucketName'
      DatasetBucketPrefix: !Ref 'DatasetS3KeyPrefix'
  CopyDataFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: !Join
          - "\n"
          - - import os
            - from concurrent.futures import ThreadPoolExecutor
            - ''
            - import boto3
            - import cfnresponse
            - import functools
            - from botocore.exceptions import ClientError
            - ''
            - 'def copy_data(event, source_key, destination_key, bucket_name):'
            - '    bucket = boto3.resource(''s3'').Bucket(bucket_name)'
            - '    copy_source = {'
            - '        ''Bucket'': event[''ResourceProperties''][''DatasetBucket''],'
            - '        ''Key'': source_key'
            - '    }'
            - '    return functools.partial(bucket.copy, copy_source, destination_key)'
            - ''
            - 'def recursive_copy_data(event, source_prefix, destination_prefix, bucket_name):'
            - '    data_bucket = boto3.resource(''s3'').Bucket(event[''ResourceProperties''][''DatasetBucket''])'
            - '    base_path = event[''ResourceProperties''][''DatasetBucketPrefix'']'
            - '    source_path = os.path.join(base_path, source_prefix)'
            - '    for obj in data_bucket.objects.filter(Prefix=source_path):'
            - '        source_key = obj.key'
            - '        destination_key = os.path.join(destination_prefix, os.path.basename(obj.key))'
            - '        yield copy_data(event, source_key, destination_key, bucket_name)'
            - ''
            - 'def generate_copy_jobs(event):'
            - '    base_path = event[''ResourceProperties''][''DatasetBucketPrefix'']'
            - '    submissions_bucket_name = event[''ResourceProperties''][''SubmissionsBucket'']'
            - '    curated_bucket_name = event[''ResourceProperties''][''CuratedBucket'']'
            - '    '
            - '    yield copy_data('
            - '        event,'
            - '        source_key=os.path.join(base_path, ''demographics20170520.zip''),'
            - '        destination_key=''demographics/2017/06/02/demographics20170520.zip'','
            - '        bucket_name=submissions_bucket_name'
            - '    )'
            - '    yield copy_data('
            - '        event,'
            - '        source_key=os.path.join(base_path, ''customers.json''),'
            - '        destination_key=''customers/2017/06/01/customers.json'','
            - '        bucket_name=submissions_bucket_name'
            - '    )'
            - '    yield copy_data('
            - '        event,'
            - '        source_key=os.path.join(base_path, ''customers_metadata.json''),'
            - '        destination_key=''metadata/customers_metadata.json'','
            - '        bucket_name=submissions_bucket_name'
            - '    )'
            - '    yield from recursive_copy_data(event, source_prefix=''orders/orders.json'',
              destination_prefix=''orders/2017/06/01/'', bucket_name=submissions_bucket_name)'
            - '    yield from recursive_copy_data(event, source_prefix=''products/products.json'',
              destination_prefix=''products/2017/06/01/'', bucket_name=submissions_bucket_name)'
            - '    '
            - '    yield from recursive_copy_data('
            - '        event, '
            - '        source_prefix=''old_versions/demographics/demographics_data.parquet'', '
            - '        destination_prefix=''demographics_20170520_parquet/dataset=demographics/v=2017-05-20/p=parquet/dt=2017-06-01/'', '
            - '        bucket_name=curated_bucket_name'
            - '    )'
            - '    for year in range(2013, 2017):'
            - '        yield from recursive_copy_data('
            - '            event,'
            - '            source_prefix=''old_versions/products/products.parquet{}''.format(year), '
            - '            destination_prefix=''products_20170601_parquet/dataset=products/v=2017-06-01/p=parquet/dt={}-12-31''.format(year), '
            - '            bucket_name=curated_bucket_name'
            - '        )'
            - ''
            - 'def handler(event, context):'
            - '    if event[''RequestType''] != ''Create'':'
            - '        return cfnresponse.send(event, context, cfnresponse.SUCCESS,
              {})'
            - '    try:'
            - '        with ThreadPoolExecutor(max_workers=7) as executor:'
            - '            futures = [executor.submit(job) for job in generate_copy_jobs(event)]'
            - '        for future in futures:'
            - '            exception = future.exception()'
            - '            if exception is not None:'
            - '                raise exception'
            - '        return cfnresponse.send(event, context, cfnresponse.SUCCESS,
              {})'
            - '    except ClientError as e:'
            - '        print(e)'
            - '        return cfnresponse.send(event, context, cfnresponse.FAILED,
              {})'
      Handler: index.handler
      Role: !Ref 'CopyDataRoleARN'
      MemorySize: 512
      Runtime: python3.6
      Timeout: 300
Parameters:
  CopyDataRoleARN:
    Description: CopyDataRole ARN
    Type: String
  DatasetS3BucketName:
    Description: Dataset bucket name for the Quick Start dataset.
    Type: String
  DatasetS3KeyPrefix:
    Description: S3 key prefix for the Quick Start dataset.
    Type: String
  SubmissionsBucketName:
    Description: SubmissionsBucket bucket name
    Type: String
  CuratedBucketName:
    Description: CuratedDatasets bucket name
    Type: String
